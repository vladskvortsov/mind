name: Deploy VPC, EC2, RDS, ElasticCache
on: 
  workflow_dispatch:
  # push:
  #   branches:
  #     - main
  #   paths:
  #     - 'project1/backend_redis/*'
  #     - 'project1/backend_rds/*'
jobs:
  deploy-rds:
    runs-on: ubuntu-latest 
    outputs:
      aws_vpc_id: ${{ steps.create_vpc.outputs.aws_vpc_id }}
      ec2_sg_id: ${{ steps.create_sg.outputs.ec2_sg_id }}
      db_sg_id: ${{ steps.create_rds_sg.outputs.db_sg_id }}
      db_endpoint: ${{ steps.get_endpoint.outputs.db_endpoint }}
      private_subnet_id: ${{ steps.subnets.outputs.private_subnet_id }}
      private_subnet_id2: ${{ steps.subnets.outputs.private_subnet_id2 }}
      public_subnet_id: ${{ steps.subnets.outputs.public_subnet_id }}
      igw_id: ${{ steps.create_igw.outputs.igw_id }}
    env:  # Set secrets as environment variables for the job
      DB_NAME: mydb
      DB_USER: dbuser
      DB_PORT: 5432
      DB_INSTANCE_IDENTIFIER: mydb
      DB_PASSWORD: Mypassword11


    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Create or Use Existing VPC
      id: create_vpc
      run: |
        VPC_ID=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=project1-vpc --query "Vpcs[0].VpcId" --output text 2>/dev/null || echo "None")
        if [ "$VPC_ID" == "None" ]; then
          VPC_ID=$(aws ec2 create-vpc --cidr-block 10.10.0.0/16 --query 'Vpc.VpcId' --output text)
          aws ec2 modify-vpc-attribute --vpc-id $VPC_ID --enable-dns-support
          aws ec2 modify-vpc-attribute --vpc-id $VPC_ID --enable-dns-hostnames
          aws ec2 create-tags --resources $VPC_ID --tags Key=Name,Value=project1-vpc
          echo "Created VPC with ID: $VPC_ID"
        else
          echo "Using existing VPC with ID: $VPC_ID"
        fi
        echo "aws_vpc_id=$VPC_ID" >> $GITHUB_OUTPUT

    - name: Create Public and Private Subnets
      id: subnets
      run: |
        PUBLIC_SUBNET_1=$(aws ec2 describe-subnets --filters Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} Name=cidr-block,Values=10.10.1.0/24 --query "Subnets[0].SubnetId" --output text 2>/dev/null || echo "None")
        if [ "$PUBLIC_SUBNET_1" == "None" ]; then
          PUBLIC_SUBNET_1=$(aws ec2 create-subnet --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} \
            --cidr-block 10.10.1.0/24 --availability-zone ${{ secrets.AWS_REGION }}a \
            --query 'Subnet.SubnetId' --output text)
          echo "Created Public Subnet 1: $PUBLIC_SUBNET_1"
        fi

        PUBLIC_SUBNET_2=$(aws ec2 describe-subnets --filters Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} Name=cidr-block,Values=10.10.2.0/24 --query "Subnets[0].SubnetId" --output text 2>/dev/null || echo "None")
        if [ "$PUBLIC_SUBNET_2" == "None" ]; then
          PUBLIC_SUBNET_2=$(aws ec2 create-subnet --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} \
            --cidr-block 10.10.2.0/24 --availability-zone ${{ secrets.AWS_REGION }}b \
            --query 'Subnet.SubnetId' --output text)
          echo "Created Public Subnet 2: $PUBLIC_SUBNET_2"
        fi

        PRIVATE_SUBNET_1=$(aws ec2 describe-subnets --filters Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} Name=cidr-block,Values=10.10.3.0/24 --query "Subnets[0].SubnetId" --output text 2>/dev/null || echo "None")
        if [ "$PRIVATE_SUBNET_1" == "None" ]; then
          PRIVATE_SUBNET_1=$(aws ec2 create-subnet --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} \
            --cidr-block 10.10.3.0/24 --availability-zone ${{ secrets.AWS_REGION }}a \
            --query 'Subnet.SubnetId' --output text)
          echo "Created Private Subnet 1: $PRIVATE_SUBNET_1"
        fi

        PRIVATE_SUBNET_2=$(aws ec2 describe-subnets --filters Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} Name=cidr-block,Values=10.10.4.0/24 --query "Subnets[0].SubnetId" --output text 2>/dev/null || echo "None")
        if [ "$PRIVATE_SUBNET_2" == "None" ]; then
          PRIVATE_SUBNET_2=$(aws ec2 create-subnet --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} \
            --cidr-block 10.10.4.0/24 --availability-zone ${{ secrets.AWS_REGION }}b \
            --query 'Subnet.SubnetId' --output text)
          echo "Created Private Subnet 2: $PRIVATE_SUBNET_2"
        fi

        echo "public_subnet_id=$PUBLIC_SUBNET_1" >> $GITHUB_OUTPUT
        echo "public_subnet_id2=$PUBLIC_SUBNET_2" >> $GITHUB_OUTPUT
        echo "private_subnet_id=$PRIVATE_SUBNET_1" >> $GITHUB_OUTPUT
        echo "private_subnet_id2=$PRIVATE_SUBNET_2" >> $GITHUB_OUTPUT

    - name: Create or Use Existing Internet Gateway
      id: create_igw
      run: |
        IGW_ID=$(aws ec2 describe-internet-gateways --filters Name=attachment.vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} --query "InternetGateways[0].InternetGatewayId" --output text 2>/dev/null || echo "None")
        if [ "$IGW_ID" == "None" ]; then
          IGW_ID=$(aws ec2 create-internet-gateway --query 'InternetGateway.InternetGatewayId' --output text)
          aws ec2 attach-internet-gateway --internet-gateway-id $IGW_ID --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }}
          echo "Created Internet Gateway: $IGW_ID"
        else
          echo "Using existing Internet Gateway: $IGW_ID"
        fi
        echo "igw_id=$IGW_ID" >> $GITHUB_OUTPUT

    - name: Create or Use Existing Public Route Table
      id: route_tables
      run: |
        PUBLIC_RT=$(aws ec2 describe-route-tables --filters Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} Name=tag:Name,Values=Public-Route-Table --query "RouteTables[0].RouteTableId" --output text 2>/dev/null || echo "None")
        if [ "$PUBLIC_RT" == "None" ]; then
          PUBLIC_RT=$(aws ec2 create-route-table --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} --query 'RouteTable.RouteTableId' --output text)
          aws ec2 create-tags --resources $PUBLIC_RT --tags Key=Name,Value=Public-Route-Table
          aws ec2 create-route --route-table-id $PUBLIC_RT --destination-cidr-block 0.0.0.0/0 --gateway-id ${{ steps.create_igw.outputs.igw_id }}
          echo "Created Public Route Table: $PUBLIC_RT"
        else
          echo "Using existing Public Route Table: $PUBLIC_RT"
        fi

        # Associate route table with public subnets
        aws ec2 associate-route-table --route-table-id $PUBLIC_RT --subnet-id ${{ steps.subnets.outputs.public_subnet_id }}
        aws ec2 associate-route-table --route-table-id $PUBLIC_RT --subnet-id ${{ steps.subnets.outputs.public_subnet_id2 }}
        echo "PUBLIC_RT=$PUBLIC_RT" >> $GITHUB_OUTPUT

    - name: Create Security Group for RDS
      id: create_rds_sg
      run: |
        RDS_SG=$(aws ec2 describe-security-groups --filters Name=group-name,Values=RDS-Security-Group Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} --query "SecurityGroups[0].GroupId" --output text 2>/dev/null || echo "None")
        if [ "$RDS_SG" == "None" ]; then
          RDS_SG=$(aws ec2 create-security-group --group-name RDS-Security-Group \
            --description "Security group for RDS" --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} --query 'GroupId' --output text)
          aws ec2 authorize-security-group-ingress --group-id $RDS_SG \
            --protocol tcp --port 5432 --cidr 0.0.0.0/0
          echo "Created RDS Security Group: $RDS_SG"
        else
          echo "Using existing RDS Security Group: $RDS_SG"
        fi
        echo "db_sg_id=$RDS_SG" >> $GITHUB_OUTPUT

    - name: Create DB Subnet Group
      id: db_subnet_group
      run: |
        DB_SUBNET_GROUP=$(aws rds describe-db-subnet-groups --db-subnet-group-name private-subnets-group --query "DBSubnetGroups[0].DBSubnetGroupName" --output text 2>/dev/null || echo "None")
        if [ "$DB_SUBNET_GROUP" == "None" ]; then
          aws rds create-db-subnet-group \
            --db-subnet-group-name "private-subnets-group" \
            --db-subnet-group-description "Subnet group for RDS in private subnets" \
            --subnet-ids ${{ steps.subnets.outputs.private_subnet_id }} ${{ steps.subnets.outputs.private_subnet_id2 }}
          echo "Created DB Subnet Group: private-subnets-group"
        else
          echo "Using existing DB Subnet Group: $DB_SUBNET_GROUP"
        fi

    - name: Create or Use Existing EC2 Security Group
      id: create_sg
      run: |
        SG_ID=$(aws ec2 describe-security-groups --filters Name=group-name,Values=EC2-SG Name=vpc-id,Values=${{ steps.create_vpc.outputs.aws_vpc_id }} --query "SecurityGroups[0].GroupId" --output text 2>/dev/null || echo "None")
        if [ "$SG_ID" == "None" ]; then
          SG_ID=$(aws ec2 create-security-group --group-name EC2-SG \
            --description "Security group for EC2" --vpc-id ${{ steps.create_vpc.outputs.aws_vpc_id }} --query 'GroupId' --output text)
          echo "Created EC2 Security Group: $SG_ID"

        aws ec2 authorize-security-group-ingress --group-id $SG_ID \
          --protocol tcp --port 22 --cidr 0.0.0.0/0
        aws ec2 authorize-security-group-ingress --group-id $SG_ID \
          --protocol tcp --port 8000 --cidr 0.0.0.0/0
        aws ec2 authorize-security-group-ingress --group-id $SG_ID \
          --protocol tcp --port 8003 --cidr 0.0.0.0/0
        echo "Ingress rules added to security group: $SG_ID"
        else
          echo "Using existing EC2 Security Group: $SG_ID"
        fi
        echo "ec2_sg_id=$SG_ID" >> $GITHUB_OUTPUT







    - name: Create RDS Instance
      id: create_rds
      run: |

        # Create the RDS instance
        aws rds create-db-instance \
          --db-instance-identifier ${{ env.DB_INSTANCE_IDENTIFIER }} \
          --db-instance-class db.t3.micro \
          --engine postgres \
          --db-name ${{ env.DB_NAME }} \
          --master-username ${{ env.DB_USER }} \
          --master-user-password ${{ env.DB_PASSWORD }} \
          --allocated-storage 20 \
          --vpc-security-group-ids ${{ steps.create_rds_sg.outputs.db_sg_id }} \
          --db-subnet-group-name "private-subnets-group" \
          --port ${{ env.DB_PORT }} \
          --no-multi-az \
          --backup-retention-period 0 # No automated backups



    - name: Retrieve RDS Endpoint
      id: get_endpoint
      run: |
        ENDPOINT=$(aws rds describe-db-instances \
          --db-instance-identifier ${{ env.DB_INSTANCE_IDENTIFIER }} \
          --query "DBInstances[0].Endpoint.Address" --output text)
        echo "RDS Endpoint: $ENDPOINT"
        echo "db_endpoint=$ENDPOINT" >> $GITHUB_OUTPUT






    # - id: deploy
    #   uses: bitovi/github-actions-deploy-rds@v0.1.6
    #   with:
    #     aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
    #     aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    #     aws_default_region: ${{ secrets.AWS_REGION }}

    #     aws_vpc_create: true
    #     aws_vpc_name: project1-vpc
    #     # aws_vpc_cidr_block: 10.0.0.0/16
    #     aws_vpc_public_subnets: 10.10.10.0/24,10.10.40.0/24
    #     aws_vpc_private_subnets: 10.10.20.0/24,10.10.30.0/24
    #     aws_vpc_availability_zones: ${{ secrets.AWS_REGION }}a,${{ secrets.AWS_REGION }}b

    #     aws_rds_db_enable: false       
    #     aws_rds_db_name: mydb
    #     aws_rds_db_user: dbuser
    #     aws_rds_db_engine: postgres
    #     aws_rds_db_port: 5432
    #     aws_rds_db_allocated_storage: 20
    #     aws_rds_db_instance_class: db.t3.micro
    #     aws_rds_db_final_snapshot:
    #     aws_rds_db_multi_az: false
    #     aws_rds_db_apply_immediately: true

    #     tf_state_bucket: project1-resources
    #     tf_state_file_name_append: rds-dev-db

    #     # tf_stack_destroy: true
    #     # tf_state_bucket_destroy: true



  

    # - name: Retrieve Public and Private Subnet IDs
    #   id: subnets  # Step ID for accessing outputs
    #   run: |
    #     ALL_SUBNETS=$(aws ec2 describe-subnets \
    #       --filters "Name=vpc-id,Values=${{ steps.deploy.outputs.aws_vpc_id }}" \
    #       --query "Subnets[].[SubnetId, MapPublicIpOnLaunch]" \
    #       --output json)

    #     # Separate subnets into public and private based on MapPublicIpOnLaunch
    #       PUBLIC_SUBNET=$(echo $ALL_SUBNETS | jq -r '.[] | select(.[1] == true) | .[0]' | head -n 1)
    #       PRIVATE_SUBNET=$(echo $ALL_SUBNETS | jq -r '.[] | select(.[1] == false) | .[0]' | head -n 1)

    #     # Store results in environment variables for use in subsequent steps
    #     echo "public_subnet_id=$PUBLIC_SUBNET" >> $GITHUB_OUTPUT
    #     echo "private_subnet_id=$PRIVATE_SUBNET" >> $GITHUB_OUTPUT




  deploy-elascticache:
    runs-on: ubuntu-latest
    needs: deploy-rds
    outputs:
      redis_connection_string_secret: ${{ steps.create-redis.outputs.redis_connection_string_secret }}
      redis_sg_id: ${{ steps.create-redis.outputs.redis_sg_id }}
    steps:
    - name: Create a Redis DB
      id: create-redis
      uses: bitovi/github-actions-deploy-redis-db@v0.1.1
      with:
        aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws_default_region: ${{ secrets.AWS_REGION }}

        aws_redis_enable: true
        aws_redis_port: 6379
        aws_redis_multi_az_enabled: false
        aws_redis_apply_immediately: true
        aws_vpc_id: ${{ needs.deploy-rds.outputs.aws_vpc_id }}
        aws_vpc_subnet_id: ${{ needs.deploy-rds.outputs.private_subnet_id }}
        aws_redis_allowed_security_groups: ${{ needs.deploy-rds.outputs.ec2_sg_id }}




  
  deploy-ec2:
    runs-on: ubuntu-latest
    needs: 
     - deploy-rds
     - deploy-elascticache
    outputs:
      instance-id: ${{ steps.create-ec2.outputs.instance-id }}
    env:  # Set secrets as environment variables for the job
      DB_NAME: mydb
      DB_USER: dbuser
      DB_PORT: 5432
      DB_PASSWORD: Mypassword11
      REDIS_PORT: 6379
      REDIS_DB: 0
      CORS_ALLOWED_ORIGINS: https://d2xytvnh88jebv.cloudfront.net
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}

    - name: Check and Create SSH Key Pair if Not Exists
      id: create_key
      run: |
        if 
          aws ec2 describe-key-pairs --key-names key 2>/dev/null; then
          echo "Key pair 'key' already exists. Skipping creation."
        else
          aws ec2 create-key-pair --key-name key --query 'KeyMaterial' --output text > github-action-key.pem
          chmod 400 github-action-key.pem
        fi
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      
    - name: Create IAM Role
      run: |
        aws iam get-role --role-name ecr-pull-role || \
        aws iam create-role --role-name ecr-pull-role \
          --assume-role-policy-document file://project1/ecr-assume-role.json

    - name: Attach ECR Permissions Policy
      run: |
        aws iam put-role-policy \
          --role-name ecr-pull-role \
          --policy-name AmazonEC2ContainerRegistryPullOnly \
          --policy-document file://project1/ecr-pull-role.json


    - name: Attach Role to the profile
      run: |
             aws iam get-instance-profile --instance-profile-name project1-ecr-access || aws iam create-instance-profile \
             --instance-profile-name project1-ecr-access


              ROLES_ATTACHED=$(aws iam get-instance-profile --instance-profile-name project1-ecr-access --query "InstanceProfile.Roles[*].RoleName" --output text)
              if [[ "$ROLES_ATTACHED" != *"$ROLE_NAME"* ]]; then
                aws iam add-role-to-instance-profile --instance-profile-name project1-ecr-access --role-name ecr-pull-role
              fi

    - name: Setup EC2
      id: create-ec2
      uses: truemark/aws-ec2-run-instance-action@v5
      with:
        security-group-id: ${{ needs.deploy-rds.outputs.ec2_sg_id }}
        subnet-id: "${{ needs.deploy-rds.outputs.public_subnet_id }}"
        name: project1-backend
        region: ${{ secrets.AWS_REGION }}
        image-id: "ami-08eb150f611ca277f"
        instance-type: "t3.micro"
        instance-profile: "project1-ecr-access"
        volume-size: 8
        associate-public-ip-address: true
        key-name: key
        terminate-on-post: false
        user-data: |
          #!/bin/bash
          apt update -y
          apt install -y docker.io awscli
          usermod -aG docker ubuntu
          systemctl restart docker
          # newgrp docker
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key  ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | docker login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
          cd /home/ubuntu/
          git clone https://github.com/vladskvortsov/mind.git
          cd mind/project1/
          echo "SECRET_KEY=my-secret-key
          DEBUG=False

          DB_NAME=${{ env.DB_NAME }}
          DB_USER=${{ env.DB_USER }}
          DB_PASSWORD=${{ env.DB_PASSWORD }}
          DB_HOST=${{ needs.deploy-rds.outputs.db_endpoint }}
          DB_PORT=${{ env.DB_PORT }}

          REDIS_HOST=${{ needs.deploy-elascticache.outputs.redis_connection_string_secret }}
          REDIS_PORT=${{ env.REDIS_PORT }}
          REDIS_DB=${{ env.REDIS_DB }}
          #REDIS_PASSWORD=mypassword

          CORS_ALLOWED_ORIGINS=${{ env.CORS_ALLOWED_ORIGINS }}" > vars.env
 
          echo '
          # version: '3.8'
          services:
            backend_rds:
              env_file:
              - vars.env
              image: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/project1-backend:backend-rds
              container_name: backend_rds
              ports:
                - "8000:8000"
              networks:
                - backend
              entrypoint: ["sh", "-c", "sleep 10 && python manage.py runserver 0.0.0.0:8000"]

            backend_redis:
              env_file:
              - vars.env
              image: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/project1-backend:backend-redis
              container_name: backend_redis
              ports:
                - "8003:8003"
              networks:
                - backend
              entrypoint: ["sh", "-c", "sleep 10 && python manage.py runserver 0.0.0.0:8003"]

          networks:
            backend:
              driver: bridge' > docker-compose.yml
          docker compose up -d

    - name: Attach Security Groups to EC2 Instance
      run: |
        aws ec2 modify-instance-attribute \
          --instance-id ${{ steps.create-ec2.outputs.instance-id }} \
          --groups ${{ needs.deploy-rds.outputs.db_sg_id }},${{ needs.deploy-elascticache.outputs.redis_sg_id }},${{ needs.deploy-rds.outputs.ec2_sg_id }}
























    # - name: Check and Create SSH Key Pair if Not Exists
    #   id: create_key
    #   run: |
    #     if 
    #       aws ec2 describe-key-pairs --key-names key 2>/dev/null; then
    #       echo "Key pair 'key' already exists. Skipping creation."
    #     else
    #       aws ec2 create-key-pair --key-name key --query 'KeyMaterial' --output text > github-action-key.pem
    #       chmod 400 github-action-key.pem
    #     fi

      # env:
      #   AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #   AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    # - name: Create setup.sh
    #   run: |
    #       echo "#!/bin/bash
    #       apt update -y
    #       apt install -y unzip docker.io docker-compose awscli
    #       usermod -aG docker ubuntu
    #       systemctl restart docker
    #       # newgrp docker
    #       sudo -u ubuntu aws configure set aws_access_key_id AWS_ACCESS_KEY_ID
    #       sudo -u ubuntu aws configure set aws_secret_access_key AWS_SECRET_ACCESS_KEY
    #       sudo -u ubuntu aws ecr get-login-password --region \$AWS_REGION | docker login --username AWS --password-stdin \$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_REGION.amazonaws.com
    #       cd /home/ubuntu/
    #       git clone https://github.com/vladskvortsov/mind.git
    #       cd mind/project1/
    #       echo \"SECRET_KEY=my-secret-key
    #       DEBUG=False

    #       DB_NAME=mydb
    #       DB_USER=dbuser
    #       # DB_PASSWORD=mypassword
    #       DB_HOST=$DB_HOST
    #       DB_PORT=5432

    #       REDIS_HOST=$REDIS_HOST
    #       REDIS_PORT=6379
    #       REDIS_DB=0
    #       #REDIS_PASSWORD=mypassword

    #       CORS_ALLOWED_ORIGINS=$CORS_ALLOWED_ORIGINS\" > vars.env

    #       echo '
    #       version: \"3.8\"
    #       services:
    #         backend_rds:
    #           env_file:
    #             - vars.env
    #           image: \$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_REGION.amazonaws.com/project1-backend:backend-rds
    #           container_name: backend_rds
    #           ports:
    #             - \"8000:8000\"
    #           networks:
    #             - backend
    #           entrypoint: [\"sh\", \"-c\", \"sleep 10 && python manage.py runserver 0.0.0.0:8000\"]

    #         backend_redis:
    #           env_file:
    #             - vars.env
    #           image: \$AWS_ACCOUNT_ID.dkr.ecr.\$AWS_REGION.amazonaws.com/project1-backend:backend-redis
    #           container_name: backend_redis
    #           ports:
    #             - \"8003:8003\"
    #           networks:
    #             - backend
    #           entrypoint: [\"sh\", \"-c\", \"sleep 10 && python manage.py runserver 0.0.0.0:8003\"]

    #       networks:
    #         backend:
    #           driver: bridge' > docker-compose.yml
          
    #       docker-compose up -d
    #       " > /home/runner/setup.sh
    #       chmod 700 /home/runner/setup.sh
    #       cd /home/runner/
    #       pwd
    #       ls

    #       VARS='SECRET_KEY=my-secret-key
    #             DEBUG=False

    #             AWS_ACCOUNT_ID=${{ secrets.AWS_ACCOUNT_ID }}
    #             AWS_REGION=${{ secrets.AWS_REGION }}
    #             AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
    #             AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}


    #             DB_NAME=mydb
    #             DB_USER=dbuser
    #             # DB_PASSWORD=mypassword
    #             DB_HOST=$DB_HOST
    #             DB_PORT=5432

    #             REDIS_HOST=$REDIS_HOST
    #             REDIS_PORT=6379
    #             REDIS_DB=0
    #             #REDIS_PASSWORD=mypassword

    #             CORS_ALLOWED_ORIGINS=$CORS_ALLOWED_ORIGINS'
    #       echo "vars=$VARS" >> $GITHUB_ENV
    #       echo "$vars"





    # - id: deploy
    #   name: Deploy EC2 and RDS
    #   uses: bitovi/github-actions-deploy-docker-to-ec2@v1.0.1
    #   with:
    #     aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
    #     aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
    #     aws_default_region: ${{ secrets.AWS_REGION }}

    #     ansible_start_docker_timeout: 600

    #     env_ghv: |
    #             SECRET_KEY=my-secret-key
    #             DEBUG=False

    #             #### AWS values
    #             AWS_ACCOUNT_ID=${{ secrets.AWS_ACCOUNT_ID }}
    #             AWS_REGION=${{ secrets.AWS_REGION }}
    #             AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
    #             AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
                
    #             #### Redis values
    #             REDIS_HOST=${{env.REDIS_HOST}}
    #             REDIS_PORT=6379
    #             REDIS_DB=0
    #             #REDIS_PASSWORD=mypassword
    #             CORS_ALLOWED_ORIGINS=${{env.CORS_ALLOWED_ORIGINS}}
    #     # env_repo: /home/runner/vars.env
    #     aws_vpc_create: true
    #     aws_vpc_name: project1-vpc
    #     # aws_vpc_cidr_block: 10.0.0.0/16
    #     aws_vpc_public_subnets: 10.10.10.0/24,10.10.40.0/24
    #     aws_vpc_private_subnets: 10.10.20.0/24,10.10.30.0/24
    #     aws_vpc_availability_zones:  ${{ secrets.AWS_REGION }}a,${{ secrets.AWS_REGION }}b
    #     aws_elb_create: false
    #     # aws_elb_app_port: 8000,8003,8080
    #     # aws_elb_listen_port: 8000,8003,80
    #     # # aws_elb_healthcheck: "HTTP:8080"

    #     aws_ec2_instance_create: true
    #     aws_ec2_instance_type: t3.micro
    #     aws_ec2_instance_root_vol_size: 8
    #     aws_ec2_port_list: 8000,8003,8080
    #     aws_ec2_iam_instance_profile: project1-ecr-access
    #     docker_repo_app_directory: ./project1/
    #     aws_ec2_user_data_file: ./project1/setup.sh
    #     aws_ec2_create_keypair_sm: false

    #     aws_rds_db_enable: true        
    #     aws_rds_db_name: mydb
    #     aws_rds_db_user: dbuser
    #     aws_rds_db_engine: postgres
    #     aws_rds_db_port: 5432
    #     aws_rds_db_allocated_storage: 20
    #     aws_rds_db_instance_class: db.t3.micro
    #     aws_rds_db_final_snapshot:
    #     aws_rds_db_multi_az: false
    #     aws_rds_db_apply_immediately: true

# tf_stack_destroy: true
# tf_state_bucket_destroy: true



    # - name: SM
    #   uses: aws-actions/aws-secretsmanager-get-secrets@v2
    #   with:
    #     secret-ids: |
    #       SM, vladskvortsov-mind-master-sm*
    #     name-transformation: uppercase
    #     parse-json-secrets: true






    
    # - name: Describe Instance
    #   id: ec2-describe
    #   uses: truemark/aws-ec2-describe-instance-action@v2
    #   with:
    #     instance-id: ${{ steps.deploy.outputs.instance-id }}
    #     region: ${{ secrets.AWS_REGION }}






    # - name: Deploy on EC2
    #   uses: appleboy/ssh-action@master
    #   with:
    #     host: 13.60.4.233
    #     username: ubuntu
    #     key: ${{ secrets.PRIVATE_KEY }}
    #     script: |       
    #           cd mind/
    #           apt update 
    #           apt install -y unzip docker
    #           curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
    #           unzip awscliv2.zip
    #           ./aws/install 
    #           sudo usermod -aG docker $USER
    #           aws ecr get-login-password --region ${{ secrets.AWS_REGION }} | docker login --username AWS --password-stdin ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com
    #           docker compose up -d


  












        
